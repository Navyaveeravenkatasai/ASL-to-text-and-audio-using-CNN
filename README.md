**ASL to Text and Audio Project**
Overview
This project is designed to translate American Sign Language (ASL) gestures into text and audio. The system uses a Convolutional Neural Network (CNN) to recognize hand gestures and convert them into corresponding text and audio outputs.

Project Structure
model1/: Directory containing trained models.
newDataset/: Directory to store the new dataset.
play/: Directory for playing/testing various components.
HandGestureRecognize/: Main directory for hand gesture recognition scripts.
run/: Main script to start the application.
test/: Directory for testing the application.
UMLs/: UML diagrams related to the project.
Screenshots
screens Hand gesture recognition and...: Screenshots of the hand gesture recognition interface.
Screens of CNN based deaf mute pe...: Screenshots of the CNN-based interface for deaf-mute persons.
How to Run
Open the Project Directory: Ensure you have navigated to the project directory in your terminal or command prompt.
Execute the Run Script: Run the following command:
sh
Copy code
python run
Select the Dataset Folder: A dialog box will appear. Select the folder containing your dataset for hand gesture recognition.
Requirements
Ensure you have the following dependencies installed:

Python 3
TensorFlow
OpenCV
NumPy
